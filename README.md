# Generative Audio from Visual Data

## Project Overview

**Disclaimer:** The contents of this file were created by AI (ChatGPT), as was much of the code in this repository. Please use with caution.

This project generates audio tracks based on visual data extracted from videos. Visual features such as color, brightness, contrast, and motion are mapped to different audio characteristics to create unique soundscapes.

## Features

- Extracts visual data from video files.
- Maps visual features to audio characteristics.
- Generates and saves audio tracks as WAV files.
- Supports various synthesis techniques including complex waveforms, additive, and subtractive synthesis.
- Configurable waveform type and output filename via command-line arguments.
- Web interface for file upload and parameter configuration.

## Getting Started

### Prerequisites

Ensure you have the following installed:
- Python 3.x
- pip (Python package installer)

### Installation

1. **Clone the Repository**

    ```bash
    git clone https://github.com/yourusername/generative-audio.git
    cd generative-audio
    ```

2. **Set Up a Virtual Environment**

    ```bash
    python -m venv myenv
    source myenv/bin/activate  # On Windows use `myenv\Scripts\activate`
    ```

3. **Install Dependencies**

    ```bash
    pip install numpy scipy flask
    ```

4. **Download Additional Requirements**

    If additional requirements are needed, list them here.

### Usage

1. **Prepare Your Video File**

   Place your video file in the `src/mp4/` directory or specify a path to your video file in the script.

2. **Run the Script to Extract Visual Data**

    ```bash
    python audio/video_to_data_v0.py --file-name yourfilename
    ```

   This script processes the video and generates JSON and CSV files with visual data. The JSON file will include the `video_duration` field, which is essential for correlating the length of the generated audio with the length of the video.

3. **Generate Audio from Visual Data**

   **Legacy Method (v0):**
   
    ```bash
    python audio/audio_from_data_v0.py
    ```

   This script creates a WAV file based on the extracted visual data using basic sine wave synthesis. It uses the `video_duration` field from the JSON file to ensure that the length of the audio file corresponds to the length of the video.

   **Enhanced Method (v1):**
   
    ```bash
    python audio/audio_from_data_v1.py --wave-type sine
    python audio/audio_from_data_v1.py --wave-type sawtooth
    python audio/audio_from_data_v1.py --wave-type square
    python audio/audio_from_data_v1.py --wave-type triangle
    python audio/audio_from_data_v1.py --wave-type additive
    python audio/audio_from_data_v1.py --wave-type subtractive
    ```

   This script creates a WAV file based on the extracted visual data using advanced synthesis techniques. It supports multiple waveform types and synthesis methods, which can be selected via command-line arguments. You can also specify the output filename using the `--file-name` argument. The `video_duration` field from the JSON file is used to ensure that the length of the audio file corresponds to the length of the video.

4. **Using the Web Interface**

   - Start the Flask server:

     ```bash
     python app.py
     ```

   - Navigate to `http://localhost:5000` in your web browser.
   - Upload your video file and configure the audio generation parameters via the web interface.

### Code

- **`video_to_data_v0.py`**: Extracts visual features from video and saves them to JSON and CSV files. Includes the `video_duration` in the JSON file for accurate audio length.
- **`audio_from_data_v0.py`**: Generates audio from the visual features data and saves it as a WAV file using basic sine wave synthesis.
- **`audio_from_data_v1.py`**: Generates audio from the visual features data and saves it as a WAV file using advanced synthesis techniques. Supports various waveform types and synthesis methods configurable via command-line arguments.
- **`app.py`**: Flask web application to upload video files, configure audio generation parameters, and visualize results.

### JSON Data Structure

The JSON file generated by the `video_to_data_v0.py` script includes:

- **video_duration**: The total duration of the video in seconds.
- **frames**: A list of dictionaries, each containing:
  - `avg_color`: Average color of the frame (list of RGB values).
  - `mass`: Mass of the frame (number of pixels within a certain color range).
  - `brightness`: Brightness of the frame.
  - `contrast`: Contrast of the frame.
  - `motion`: Motion detected in the frame.

### Dependencies

- **numpy**: For numerical operations.
- **scipy**: For audio file handling.
- **flask**: For the web interface.

### Troubleshooting

If you encounter issues:

- Check if the directory paths are correct.
- Ensure that all dependencies are installed.
- Verify that your internet connection is stable if you're installing packages.
- Make sure the JSON file structure matches the expected format with `video_duration` and `frames`.

### Contributing

Feel free to submit issues or pull requests if you have suggestions or improvements for the project.

### License

Specify the license under which your project is distributed.
